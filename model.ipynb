{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import gzip\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelDimensions:\n",
    "    n_mels: int\n",
    "    n_audio_ctx: int\n",
    "    n_audio_state: int\n",
    "    n_audio_head: int\n",
    "    n_audio_layer: int\n",
    "    n_vocab: int\n",
    "    n_text_ctx: int\n",
    "    n_text_state: int\n",
    "    n_text_head: int\n",
    "    n_text_layer: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.LayerNorm):\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return super().forward(x.float()).type(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Linear):\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return F.linear(x, self.weight.to(x.dtype), None if self.bias is None else self.bias.to(x.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(nn.Conv1d):\n",
    "    def _conv_forward(self, x: Tensor, weight: Tensor, bias: Optional[Tensor]) -> Tensor:\n",
    "        return super()._conv_forward(x, weight.to(x.dtype), None if bias is None else bias.to(x.dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 15976])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek conv1d\n",
    "x = torch.randn(1, 1, 16000)\n",
    "c = Conv1d(1, 16, 25)\n",
    "o = c(x)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoids(length, channels, max_timescale=10000):\n",
    "    # channels dim needs to be even because, we need split it half and process with sin and cos\n",
    "    assert channels % 2 == 0\n",
    "\n",
    "    # todo\n",
    "    log_timescale_increment = np.log(max_timescale) / (channels // 2 - 1)\n",
    "\n",
    "    # todo\n",
    "    inv_timescales = torch.exp(-log_timescale_increment * torch.arange(channels // 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+00, 1.0000e-04])\n",
      "tensor([[0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 1.0000e-04],\n",
      "        [2.0000e+00, 2.0000e-04],\n",
      "        [3.0000e+00, 3.0000e-04],\n",
      "        [4.0000e+00, 4.0000e-04]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels = 4\n",
    "length = 5\n",
    "max_timescale = 10000\n",
    "log_timescale_increment = np.log(max_timescale) / (channels // 2 - 1)\n",
    "-log_timescale_increment * torch.arange(channels // 2)\n",
    "inv_t = torch.exp(-log_timescale_increment * torch.arange(channels // 2))\n",
    "print(inv_t)\n",
    "scaled_time = torch.arange(length)[:, np.newaxis] * inv_t[np.newaxis, :]\n",
    "print(scaled_time)\n",
    "torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoids(length, channels, max_timescale=10000):\n",
    "    \n",
    "    return torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)], dim=1)\n",
    "    # 6. Compute and concatenate sine and cosine values\n",
    "    # Apply sine and cosine functions to the scaled time\n",
    "    # Concatenate the results along the second dimension (dim=1) to get the final positional encodings\n",
    "\n",
    "# Example usage:\n",
    "length = 10  # sequence length\n",
    "channels = 6  # number of dimensions for positional encoding\n",
    "max_timescale = 1000  # maximum timescale\n",
    "\n",
    "pos_encodings = sinusoids(length, channels, max_timescale)\n",
    "print(pos_encodings.shape)  # Should output: torch.Size([10, 6])\n",
    "print(pos_encodings)  # Will show the actual positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoids(length, channels, max_timescale=10000):\n",
    "    \"\"\"Returns sinusoids for positional embedding\"\"\"\n",
    "    assert channels % 2 == 0\n",
    "    log_timescale_increment = np.log(max_timescale) / (channels // 2 - 1)\n",
    "    inv_timescales = torch.exp(-log_timescale_increment * torch.arange(channels // 2))\n",
    "    scaled_time = torch.arange(length)[:, np.newaxis] * inv_timescales[np.newaxis, :]\n",
    "    return torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)], dim=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
